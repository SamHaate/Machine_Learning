{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6b76d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTING LIBRARIES\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed31d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLASSES\n",
    "#0 - Speed limit (20km/h)  \n",
    "#1 - Speed limit (30km/h)  \n",
    "#2 - Speed limit (50km/h)  \n",
    "#3 - Speed limit (60km/h)  \n",
    "#4 - Speed limit (70km/h)  \n",
    "#5 - Speed limit (80km/h)  \n",
    "#6 - End of speed limit (80km/h)  \n",
    "#7 - Speed limit (100km/h)  \n",
    "#8 - Speed limit (120km/h)  \n",
    "#9 - No passing  \n",
    "#10 - No passing for vehicles over 3.5 metric tons  \n",
    "#11 - Right-of-way at the next intersection  \n",
    "#12 - Priority road  \n",
    "#13 - Yield  \n",
    "#14 - Stop  \n",
    "#15 - No vehicles  \n",
    "#16 - Vehicles over 3.5 metric tons prohibited  \n",
    "#17 - No entry  \n",
    "#18 - General caution  \n",
    "#19 - Dangerous curve to the left  \n",
    "#20 - Dangerous curve to the right  \n",
    "#21 - Double curve  \n",
    "#22 - Bumpy road  \n",
    "#23 - Slippery road  \n",
    "#24 - Road narrows on the right  \n",
    "#25 - Road work  \n",
    "#26 - Traffic signals  \n",
    "#27 - Pedestrians  \n",
    "#28 - Children crossing  \n",
    "#29 - Bicycles crossing  \n",
    "#30 - Beware of ice/snow  \n",
    "#31 - Wild animals crossing  \n",
    "#32 - End of all speed and passing limits  \n",
    "#33 - Turn right ahead  \n",
    "#34 - Turn left ahead  \n",
    "#35 - Ahead only  \n",
    "#36 - Go straight or right  \n",
    "#37 - Go straight or left  \n",
    "#38 - Keep right  \n",
    "#39 - Keep left  \n",
    "#40 - Roundabout mandatory  \n",
    "#41 - End of no passing  \n",
    "#42 - End of no passing by vehicles over 3.5 metric tons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e006c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTING THE DATASET\n",
    "\n",
    "with open(\"./traffic-signs-data/train.p\", mode='rb') as training_data:\n",
    "    train = pickle.load(training_data)\n",
    "with open(\"./traffic-signs-data/valid.p\", mode='rb') as validation_data:\n",
    "    valid = pickle.load(validation_data)\n",
    "with open(\"./traffic-signs-data/test.p\", mode='rb') as testing_data:\n",
    "    test = pickle.load(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b16ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATING TRAINING, VALIDATION AND TESTING DATA\n",
    "\n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_validation, y_validation = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8303a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRINTING A MATRIX OF IMAGES  AND LABELS AT RANDOM\n",
    "\n",
    "W_grid = 15\n",
    "L_grid = 15\n",
    "n_training = len(X_train)\n",
    "\n",
    "fig, axes = plt.subplots(L_grid, W_grid, figsize=(20,20))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in np.arange(0, L_grid * W_grid):\n",
    "    index = np.random.randint(0,n_training)\n",
    "    axes[i].imshow(X_train[index])\n",
    "    axes[i].set_title(y_train[index], fontsize = 7)\n",
    "    axes[i].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8f8073",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING THE SHAPES OF THE DATA\n",
    "\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"X_validation shape: \", X_validation.shape)\n",
    "print(\"y_validation shape: \", y_validation.shape)\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "print(\"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf90d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VISUALIZING THE DATA\n",
    "\n",
    "i=1000\n",
    "plt.imshow(X_train[i])\n",
    "y_train[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7f4401",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHUFFLING THE ORDER OF THE DATA\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1164ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GREYSCALING THE DATA\n",
    "\n",
    "X_train_gray = np.sum(X_train/3, axis=3, keepdims=True)\n",
    "X_validation_gray = np.sum(X_validation/3, axis=3, keepdims=True)\n",
    "X_test_gray = np.sum(X_test/3, axis=3, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fd715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING NEW SHAPE OF THE DATA\n",
    "\n",
    "print(\"X_train_gray shape: \", X_train_gray.shape)\n",
    "print(\"X_validation_gray shape: \", X_validation_gray.shape)\n",
    "print(\"X_test_gray shape: \", X_test_gray.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9d0fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NORMALIZING THE DATA\n",
    "\n",
    "X_train_gray_norm = (X_train_gray - 128)/128\n",
    "X_validation_gray_norm = (X_validation_gray - 128)/128\n",
    "X_test_gray_norm = (X_test_gray - 128)/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9374834a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VISUALIZING THE GRAYSCALED AND NORMALIZED DATA\n",
    "\n",
    "i=610\n",
    "plt.imshow(X_train[i])\n",
    "plt.figure()\n",
    "plt.imshow(X_train_gray[i].squeeze(), cmap='gray')\n",
    "plt.figure()\n",
    "plt.imshow(X_train_gray_norm[i].squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d13229e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BUILDING THE CNN - LE-NET DERIVED DEEP NETWORK\n",
    "\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "#Initializing\n",
    "cnn = Sequential()\n",
    "\n",
    "#First Convolutional Layer\n",
    "cnn.add(Conv2D(filters = 6, kernel_size = (5,5), activation = 'relu', input_shape = (32,32,1)))\n",
    "\n",
    "#Batch Normalization\n",
    "cnn.add(BatchNormalization())\n",
    "\n",
    "#First Pooling Layer\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#Second Convolutional Layer\n",
    "cnn.add(Conv2D(filters = 16, kernel_size = (5,5), activation = 'relu'))\n",
    "\n",
    "#Batch Normalization\n",
    "cnn.add(BatchNormalization())\n",
    "\n",
    "#Second Pooling Layer\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#Third Convolutional Layer\n",
    "cnn.add(Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu'))\n",
    "\n",
    "#Batch Normalization\n",
    "cnn.add(BatchNormalization())\n",
    "\n",
    "#Second Pooling Layer\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#Flattening\n",
    "cnn.add(Flatten())\n",
    "\n",
    "#First Fully Connected Layer\n",
    "cnn.add(Dense(units = 120, activation = 'relu'))\n",
    "\n",
    "#Dropout Layer\n",
    "cnn.add(Dropout(0.5))\n",
    "\n",
    "#Second Fully Connected Layer\n",
    "cnn.add(Dense(units = 84, activation = 'relu'))\n",
    "\n",
    "#Dropout Layer\n",
    "cnn.add(Dropout(0.5))\n",
    "\n",
    "#Output Layer\n",
    "cnn.add(Dense(units = 43, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b90a259",
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMPILING THE CNN\n",
    "\n",
    "cnn.compile(optimizer = Adam(learning_rate=0.0003), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6279325c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENHANCEMENTS - EARLY STOPPING\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=30, restore_best_weights=True, min_delta=0.0005)\n",
    "reduced_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=30, verbose=1, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683b8eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENHANCEMENTS - IMAGE AUGMENTATION\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range = 10,zoom_range = 0.1,width_shift_range = 0.1,height_shift_range = 0.1,horizontal_flip = True)\n",
    "datagen.fit(X_train_gray_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d358d863",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING THE CNN - DATA AUGMENTATION\n",
    "\n",
    "history = cnn.fit(datagen.flow(X_train_gray_norm, y_train, batch_size=250),epochs=300, validation_data=(X_validation_gray_norm, y_validation), callbacks=[early_stopping,reduced_lr], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e29cde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING THE CNN\n",
    "\n",
    "#history = cnn.fit(X_train_gray_norm, y_train, batch_size = 250, epochs = 250, validation_data = (X_validation_gray_norm, y_validation), verbose = 1, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e9894d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVALUATING THE CNN\n",
    "\n",
    "score = cnn.evaluate(X_test_gray_norm, y_test)\n",
    "print('Test Accuracy: {}'.format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4756d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING THE KEYS IN THE HISTORY\n",
    "\n",
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2deaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVALUATING THE HISTORY\n",
    "\n",
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7120a11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VISUALIZING THE ACCURACY\n",
    "\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "#VISUALIZING THE LOSS\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807fe853",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREDICTING THE TESTING DATA\n",
    "\n",
    "predicted_classes = cnn.predict(X_test_gray_norm)\n",
    "y_true = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab7afea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONFUSION MATRIX\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_true, np.argmax(predicted_classes, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4a2f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOTTING THE CONFUSION MATRIX\n",
    "\n",
    "plt.figure(figsize=(20, 15))\n",
    "sns.heatmap(cm, annot=True, cmap='viridis', xticklabels=range(43), yticklabels=range(43), fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1264d8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOTTING PREDICTIONS TO TRUE VALUES\n",
    "L = 7\n",
    "W = 7\n",
    "fig, axes = plt.subplots(L, W, figsize=(20, 15))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in np.arange(0, L * W):\n",
    "    axes[i].imshow(X_test[i])\n",
    "    axes[i].set_title('Prediction = {}\\n True = {}'.format(np.argmax(predicted_classes[i]), y_true[i]))\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.subplots_adjust(wspace=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
